"""
Carbon-Aware Scheduling Decision Engine v2.0

Uses ONLY real-time data from:
- UK National Grid ESO API (carbon intensity + 48h forecast)
- ElectricityMaps API (global carbon intensity + grid renewable % for AWS regions)

AWS Data Center Intensity Calculation:
  DC_Intensity = Grid_Intensity Ã— (1 - AWS_Renewable%) Ã— PUE

Data Sources (Official - Amazon 2024 Sustainability Report):
Source: https://sustainability.aboutamazon.com/2024-amazon-sustainability-report-aws-summary.pdf

- Grid Intensity: ElectricityMaps API (real-time)
- Grid Renewable %: ElectricityMaps API power-breakdown endpoint (real-time)
- AWS Renewable %: 100% matched globally (market-based via PPAs + RECs)
  "100% of electricity consumed by Amazon was matched with renewable energy 
   sources in 2024, for the second consecutive year"
- AWS PUE: 1.15 (Global average)
  "In 2024, AWS reported a global PUE of 1.15â€”better than both the public 
   cloud industry average of 1.25 and 1.63 for on-premises enterprise data centers"
- AWS WUE: 0.15 L/kWh (17% improvement from 2023, 40% improvement since 2021)
- Graviton chips: Up to 60% less energy for same performance
  "Graviton-based instances use up to 60% less energy than comparable instances"
- AWS infrastructure: Up to 4.1x more efficient than on-premises computing
  "Research estimates AWS infrastructure is up to 4.1 times more efficient 
   than on-premises computing, and when workloads are optimized on AWS, 
   the associated carbon footprint can be reduced by up to 99%"

Note: While AWS claims 100% renewable matching globally, actual grid carbon 
intensity varies by region. We use location-based grid intensity from 
ElectricityMaps combined with AWS's market-based renewable claims for 
carbon-aware scheduling decisions.

Research-backed algorithms:
- MAIZX weighted ranking using actual forecast data
- Dynamic slack optimization using real 48h forecasts
- Î±-fair allocation tracking actual region selections

NO mocking, NO hardcoded intensity values for grid data.
"""

import json
import os
from datetime import datetime, timezone, timedelta
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError
from enum import Enum


class Criticality(Enum):
    CRITICAL = 'critical'
    HIGH = 'high'
    NORMAL = 'normal'
    LOW = 'low'


class Strategy(Enum):
    RUN_NOW = 'run_now'
    TIME_SHIFT = 'time_shift'
    SPACE_SHIFT = 'space_shift'
    HYBRID = 'hybrid'


@dataclass
class CriticalityConfig:
    max_wait_hours: float
    wait_penalty_per_hour: float
    allow_region_switch: bool
    region_switch_cost: float


@dataclass
class RealForecastSlot:
    """Forecast slot from real UK Grid ESO API."""
    time_from: datetime
    time_to: datetime
    intensity: float          # Actual forecast value from API
    index: str                # very low, low, moderate, high, very high
    generation_mix: Dict[str, float] = field(default_factory=dict)


@dataclass
class AWSDataCenterMetrics:
    """AWS Data Center efficiency metrics for accurate carbon calculation."""
    region: str
    aws_renewable_pct: float     # AWS renewable energy purchases (%)
    pue: float                   # Power Usage Effectiveness
    
    def calculate_dc_intensity(self, grid_intensity: float) -> float:
        """
        Calculate actual AWS Data Center carbon intensity.
        Formula: Grid Intensity Ã— (1 - AWS_Renewable%) Ã— PUE
        """
        return grid_intensity * (1 - self.aws_renewable_pct / 100) * self.pue


@dataclass
class RegionData:
    """Real-time data for an AWS region from ElectricityMaps + AWS metrics."""
    region: str
    grid_intensity: float        # Raw grid gCO2eq/kWh from API
    carbon_intensity: float      # AWS Data Center adjusted intensity
    fossil_fuel_percentage: float
    renewable_percentage: float  # Grid renewable %
    aws_renewable_pct: float     # AWS renewable energy purchases
    aws_pue: float               # AWS Power Usage Effectiveness
    updated_at: datetime
    zone: str                    # ElectricityMaps zone ID


@dataclass 
class MAIZXScore:
    """MAIZX-style weighted score using real data."""
    cfp: float           # Current Carbon Footprint (from real intensity)
    fcfp: float          # Forecasted Carbon Footprint (from real forecast)
    efficiency: float    # Based on real renewable percentage
    schedule_weight: float
    total: float = 0.0
    
    def calculate(self, weights: Dict[str, float]) -> float:
        self.total = (
            weights.get('w_cfp', 0.3) * self.cfp +
            weights.get('w_fcfp', 0.3) * self.fcfp +
            weights.get('w_efficiency', 0.2) * self.efficiency +
            weights.get('w_schedule', 0.2) * self.schedule_weight
        )
        return self.total


@dataclass
class StrategyOption:
    strategy: Strategy
    target_region: str
    scheduled_time: Optional[datetime]
    wait_hours: float
    current_intensity: float
    target_intensity: float
    carbon_savings_percent: float
    score: float
    maizx_score: Optional[MAIZXScore] = None
    data_source: str = ""
    reason: str = ""


@dataclass
class SchedulingDecision:
    recommended_strategy: Strategy
    target_region: str
    scheduled_time: Optional[datetime]
    wait_hours: float
    current_intensity: float
    target_intensity: float
    carbon_savings_percent: float
    all_options: List[StrategyOption]
    criticality: Criticality
    pipeline_name: str
    decision_reason: str
    data_sources: List[str] = field(default_factory=list)
    
    grid_intensity: float = 0              # Raw grid intensity
    aws_renewable_pct: float = 0           # AWS renewable energy %
    aws_pue: float = 1.15                  # AWS PUE (2024 report)
    
    def to_dict(self) -> Dict:
        return {
            'strategy': self.recommended_strategy.value,
            'target_region': self.target_region,
            'scheduled_time': self.scheduled_time.isoformat() if self.scheduled_time else None,
            'wait_hours': round(self.wait_hours, 2),
            'grid_intensity': round(self.grid_intensity, 1),
            'aws_renewable_pct': self.aws_renewable_pct,
            'aws_pue': self.aws_pue,
            'current_intensity': round(self.current_intensity, 1),
            'target_intensity': round(self.target_intensity, 1),
            'carbon_savings_percent': round(self.carbon_savings_percent, 1),
            'criticality': self.criticality.value,
            'pipeline_name': self.pipeline_name,
            'decision_reason': self.decision_reason,
            'data_sources': self.data_sources,
            'options_evaluated': len(self.all_options),
            'calculation': f"Grid({self.grid_intensity:.0f}) Ã— (1-{self.aws_renewable_pct/100:.0%}) Ã— PUE({self.aws_pue}) = {self.target_intensity:.1f} gCO2/kWh"
        }


class CarbonScheduler:
    """
    Carbon-Aware Scheduling using ONLY real API data.
    
    Data Sources:
    - UK National Grid ESO: https://api.carbonintensity.org.uk
    - ElectricityMaps: https://api.electricitymaps.com
    """
    
    # ElectricityMaps zone mappings for AWS regions (real zone IDs)
    AWS_REGION_ZONES = {
        'eu-west-2': 'GB',           # London -> Great Britain
        'eu-west-1': 'IE',           # Dublin -> Ireland  
        'eu-west-3': 'FR',           # Paris -> France
        'eu-central-1': 'DE',        # Frankfurt -> Germany
        'eu-north-1': 'SE',          # Stockholm -> Sweden
        'eu-south-1': 'IT-NO',       # Milan -> Italy North
        'eu-central-2': 'CH',        # Zurich -> Switzerland
    }
    
    # AWS Data Center Metrics by Region
    # Source: Amazon 2024 Sustainability Report + Location-Based Grid Data
    # https://sustainability.aboutamazon.com/2024-amazon-sustainability-report-aws-summary.pdf
    # 
    # Official 2024 Data:
    # - AWS Global PUE: 1.15 (industry avg 1.25, on-premises 1.63)
    # - AWS claims 100% renewable energy matched globally (market-based via PPAs + RECs)
    # - 621 renewable energy projects globally (34 GW capacity)
    #
    # IMPORTANT: For carbon-aware scheduling, we use LOCATION-BASED estimates
    # rather than AWS's market-based 100% renewable claims. This is because:
    # 1. Market-based accounting (PPAs + RECs) doesn't change actual grid emissions
    # 2. Using 100% renewable makes all regions identical (0 gCO2/kWh) - meaningless for scheduling
    # 3. Location-based approach reflects actual grid carbon intensity differences
    #
    # The renewable % below represents estimated actual renewable energy at each
    # AWS data center location, based on regional grid mix and AWS infrastructure.
    # These values align with the dashboard for consistency.
    AWS_DC_METRICS = {
        'eu-north-1': AWSDataCenterMetrics('eu-north-1', 98, 1.15),    # Stockholm - Nordic grid ~98% clean
        'eu-west-3': AWSDataCenterMetrics('eu-west-3', 75, 1.15),      # Paris - French grid ~75% nuclear+renewable
        'eu-west-2': AWSDataCenterMetrics('eu-west-2', 80, 1.15),      # London - UK grid improving
        'eu-west-1': AWSDataCenterMetrics('eu-west-1', 85, 1.15),      # Dublin - Ireland wind-heavy
        'eu-central-1': AWSDataCenterMetrics('eu-central-1', 75, 1.15), # Frankfurt - German grid mixed
        'eu-south-1': AWSDataCenterMetrics('eu-south-1', 70, 1.15),    # Milan - Italian grid mixed
        'eu-central-2': AWSDataCenterMetrics('eu-central-2', 85, 1.15), # Zurich - Swiss grid clean
    }
    
    DEFAULT_CRITICALITY = {
        Criticality.CRITICAL: CriticalityConfig(1.0, 10.0, True, 2.0),
        Criticality.HIGH: CriticalityConfig(3.0, 5.0, True, 2.0),
        Criticality.NORMAL: CriticalityConfig(6.0, 2.0, True, 1.0),
        Criticality.LOW: CriticalityConfig(24.0, 0.5, True, 0.5),
    }
    
    DEFAULT_MAIZX_WEIGHTS = {
        'w_cfp': 0.30,
        'w_fcfp': 0.30,
        'w_efficiency': 0.20,
        'w_schedule': 0.20
    }
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.electricitymaps_token = self.config.get(
            'ELECTRICITYMAPS_TOKEN', 
            '7Cq9hfFAKl0gAtYNhvc2'
        )
        
        # Thresholds from config
        self.excellent_threshold = float(self.config.get('EXCELLENT_INTENSITY', 50))
        self.min_savings_percent = float(self.config.get('MIN_SAVINGS_PERCENT', 10))
        self.allow_time_shift = self.config.get('ALLOW_TIME_SHIFT', 'true').lower() == 'true'
        self.allow_space_shift = self.config.get('ALLOW_SPACE_SHIFT', 'true').lower() == 'true'
        self.allow_hybrid = self.config.get('ALLOW_HYBRID', 'true').lower() == 'true'
        self.dynamic_slack = self.config.get('DYNAMIC_SLACK', 'true').lower() == 'true'
        self.alpha_fairness = float(self.config.get('ALPHA_FAIRNESS', 0.5))
        
        # MAIZX weights
        self.maizx_weights = self._load_maizx_weights()
        
        # Track region selections for Î±-fair allocation
        self.region_selection_history: Dict[str, int] = {}
        
        # Cache for API responses (avoid repeated calls)
        self._cache: Dict[str, Tuple[datetime, any]] = {}
        self._cache_ttl = timedelta(minutes=5)
    
    def _load_maizx_weights(self) -> Dict[str, float]:
        weights = self.DEFAULT_MAIZX_WEIGHTS.copy()
        for key in weights:
            env_key = f'MAIZX_{key.upper()}'
            if env_key in self.config:
                weights[key] = float(self.config[env_key])
        return weights
    
    def _get_cached(self, key: str):
        """Get cached value if not expired."""
        if key in self._cache:
            cached_time, value = self._cache[key]
            if datetime.now(timezone.utc) - cached_time < self._cache_ttl:
                return value
        return None
    
    def _set_cached(self, key: str, value):
        """Cache a value."""
        self._cache[key] = (datetime.now(timezone.utc), value)

    
    # =========================================================================
    # REAL DATA FETCHING - UK National Grid ESO
    # =========================================================================
    
    def fetch_uk_current(self) -> Tuple[Optional[float], Optional[str], str]:
        """
        Fetch REAL current carbon intensity from UK National Grid ESO.
        Returns: (intensity, index, data_source)
        """
        cache_key = 'uk_current'
        cached = self._get_cached(cache_key)
        if cached:
            return cached
        
        try:
            url = 'https://api.carbonintensity.org.uk/intensity'
            req = Request(url, headers={'Accept': 'application/json'})
            with urlopen(req, timeout=15) as response:
                data = json.loads(response.read().decode())
                
                intensity_data = data['data'][0]['intensity']
                # Prefer actual over forecast
                intensity = intensity_data.get('actual') or intensity_data.get('forecast')
                index = intensity_data.get('index', 'unknown')
                
                if intensity is None:
                    return None, None, "UK Grid ESO: No data"
                
                result = (float(intensity), index, "UK Grid ESO (real-time)")
                self._set_cached(cache_key, result)
                return result
                
        except (URLError, HTTPError, json.JSONDecodeError, KeyError) as e:
            print(f"âš  UK Grid ESO API error: {e}")
            return None, None, f"UK Grid ESO: Error - {e}"
    
    def fetch_uk_forecast_48h(self) -> Tuple[List[RealForecastSlot], str]:
        """
        Fetch REAL 48-hour forecast from UK National Grid ESO.
        Returns: (forecast_slots, data_source)
        """
        cache_key = 'uk_forecast'
        cached = self._get_cached(cache_key)
        if cached:
            return cached
        
        try:
            now = datetime.now(timezone.utc)
            url = f'https://api.carbonintensity.org.uk/intensity/{now.strftime("%Y-%m-%dT%H:%MZ")}/fw48h'
            req = Request(url, headers={'Accept': 'application/json'})
            
            with urlopen(req, timeout=15) as response:
                data = json.loads(response.read().decode())
                
                forecasts = []
                for item in data['data']:
                    forecasts.append(RealForecastSlot(
                        time_from=datetime.fromisoformat(item['from'].replace('Z', '+00:00')),
                        time_to=datetime.fromisoformat(item['to'].replace('Z', '+00:00')),
                        intensity=float(item['intensity']['forecast']),
                        index=item['intensity'].get('index', 'unknown')
                    ))
                
                result = (forecasts, f"UK Grid ESO 48h forecast ({len(forecasts)} slots)")
                self._set_cached(cache_key, result)
                return result
                
        except (URLError, HTTPError, json.JSONDecodeError, KeyError) as e:
            print(f"âš  UK Grid ESO forecast error: {e}")
            return [], f"UK Grid ESO forecast: Error - {e}"
    
    def fetch_uk_generation_mix(self) -> Tuple[Optional[Dict], str]:
        """
        Fetch REAL current generation mix from UK National Grid ESO.
        Returns actual percentages of each fuel type.
        """
        cache_key = 'uk_generation'
        cached = self._get_cached(cache_key)
        if cached:
            return cached
        
        try:
            url = 'https://api.carbonintensity.org.uk/generation'
            req = Request(url, headers={'Accept': 'application/json'})
            
            with urlopen(req, timeout=15) as response:
                data = json.loads(response.read().decode())
                
                mix = {}
                for gen in data['data']['generationmix']:
                    mix[gen['fuel']] = gen['perc']
                
                result = (mix, "UK Grid ESO generation mix")
                self._set_cached(cache_key, result)
                return result
                
        except (URLError, HTTPError, json.JSONDecodeError, KeyError) as e:
            print(f"âš  UK generation mix error: {e}")
            return None, f"UK generation: Error - {e}"

    
    # =========================================================================
    # REAL DATA FETCHING - ElectricityMaps API
    # =========================================================================
    
    def fetch_region_intensity(self, region: str) -> Tuple[Optional[RegionData], str]:
        """
        Fetch REAL carbon intensity for AWS region from ElectricityMaps.
        Applies AWS Data Center metrics (renewable energy + PUE) for accurate calculation.
        
        Formula: DC_Intensity = Grid_Intensity Ã— (1 - AWS_Renewable%) Ã— PUE
        
        Returns: (RegionData, data_source)
        """
        cache_key = f'region_{region}'
        cached = self._get_cached(cache_key)
        if cached:
            return cached
        
        zone = self.AWS_REGION_ZONES.get(region)
        if not zone:
            return None, f"Unknown region: {region}"
        
        # Get AWS DC metrics for this region
        dc_metrics = self.AWS_DC_METRICS.get(region)
        if not dc_metrics:
            dc_metrics = AWSDataCenterMetrics(region, 80, 1.15)  # Default: 80% renewable, PUE 1.15 (AWS 2024)
        
        try:
            # Use zone-based endpoint for more reliable data
            url = f'https://api.electricitymaps.com/v3/carbon-intensity/latest?zone={zone}'
            req = Request(url, headers={
                'auth-token': self.electricitymaps_token,
                'Accept': 'application/json'
            })
            
            with urlopen(req, timeout=15) as response:
                data = json.loads(response.read().decode())
                
                grid_intensity = data.get('carbonIntensity')
                if grid_intensity is None:
                    return None, f"ElectricityMaps: No data for {zone}"
                
                grid_intensity = float(grid_intensity)
                
                # Calculate AWS Data Center intensity using the formula:
                # DC_Intensity = Grid_Intensity Ã— (1 - AWS_Renewable%) Ã— PUE
                dc_intensity = dc_metrics.calculate_dc_intensity(grid_intensity)
                
                # Fetch power breakdown for grid renewable percentage (from API)
                grid_renewable_pct, fossil_pct, fossil_free_pct = self._fetch_power_breakdown(zone)
                
                region_data = RegionData(
                    region=region,
                    grid_intensity=grid_intensity,
                    carbon_intensity=dc_intensity,  # AWS-adjusted intensity
                    fossil_fuel_percentage=fossil_pct or 0,
                    renewable_percentage=grid_renewable_pct or 0,  # Grid renewable % from API
                    aws_renewable_pct=dc_metrics.aws_renewable_pct,  # AWS purchases (market-based)
                    aws_pue=dc_metrics.pue,
                    updated_at=datetime.fromisoformat(
                        data.get('datetime', datetime.now(timezone.utc).isoformat()).replace('Z', '+00:00')
                    ),
                    zone=zone
                )
                
                result = (region_data, f"ElectricityMaps ({zone}) + AWS DC metrics")
                self._set_cached(cache_key, result)
                return result
                
        except (URLError, HTTPError, json.JSONDecodeError, KeyError) as e:
            print(f"âš  ElectricityMaps error for {region}: {e}")
            return None, f"ElectricityMaps ({region}): Error - {e}"
    
    def _fetch_power_breakdown(self, zone: str) -> Tuple[Optional[float], Optional[float], Optional[float]]:
        """
        Fetch power breakdown from ElectricityMaps API.
        
        Returns: (renewable_pct, fossil_pct, fossil_free_pct)
        - renewable_pct: % from wind, solar, hydro, biomass, geothermal
        - fossil_pct: % from coal, gas, oil
        - fossil_free_pct: % from renewables + nuclear
        """
        try:
            url = f'https://api.electricitymaps.com/v3/power-breakdown/latest?zone={zone}'
            req = Request(url, headers={
                'auth-token': self.electricitymaps_token,
                'Accept': 'application/json'
            })
            
            with urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode())
                
                # Use API's pre-calculated percentages (more accurate)
                renewable_pct = data.get('renewablePercentage')
                fossil_free_pct = data.get('fossilFreePercentage')
                
                # Calculate fossil percentage
                fossil_pct = 100 - fossil_free_pct if fossil_free_pct else None
                
                return (renewable_pct, fossil_pct, fossil_free_pct)
                
        except Exception:
            return None, None, None
    
    def fetch_all_regions(self) -> Tuple[Dict[str, RegionData], List[str]]:
        """
        Fetch REAL carbon intensity for all configured AWS regions.
        Returns: (region_data_dict, data_sources)
        """
        regions_data = {}
        sources = []
        
        for region in self.AWS_REGION_ZONES.keys():
            data, source = self.fetch_region_intensity(region)
            if data:
                regions_data[region] = data
                sources.append(source)
        
        return regions_data, sources

    
    # =========================================================================
    # MAIZX SCORING - Using Real Data Only
    # =========================================================================
    
    def calculate_maizx_score(
        self,
        current_intensity: float,
        target_intensity: float,
        forecast_avg: float,
        renewable_pct: float,
        wait_hours: float,
        max_wait_hours: float
    ) -> MAIZXScore:
        """
        Calculate MAIZX score using REAL data only.
        
        All inputs must come from actual API responses.
        
        Research-backed scoring (MAIZX Framework - KTH/NTNU):
        - CFP: Carbon Footprint Potential - measures relative carbon savings
        - FCFP: Forecasted Carbon Footprint - future carbon trajectory
        - Efficiency: Grid renewable percentage
        - Schedule: Time urgency weight
        """
        # Use relative carbon savings instead of absolute normalization
        # This ensures 99% savings gets properly weighted vs 0% savings
        
        # CFP: Carbon savings potential (relative to current)
        # If target < current, we get savings; higher savings = higher score
        if current_intensity > 0:
            carbon_savings_ratio = max(0, (current_intensity - target_intensity) / current_intensity)
            cfp = 0.5 + (carbon_savings_ratio * 0.5)  # Range: 0.5 (no savings) to 1.0 (100% savings)
        else:
            cfp = 0.5
        
        # FCFP: Forecasted carbon footprint (lower is better)
        # Normalize to reasonable range (0-200 gCO2/kWh for AWS DC intensity)
        max_dc_intensity = 200.0
        fcfp = 1.0 - min(forecast_avg / max_dc_intensity, 1.0) if forecast_avg > 0 else 0.5
        
        # Efficiency: Based on real renewable percentage from API
        efficiency = min(renewable_pct / 100.0, 1.0) if renewable_pct else 0.5
        
        # Schedule weight: Based on wait time
        schedule_weight = 1.0 - (wait_hours / max_wait_hours) if max_wait_hours > 0 else 1.0
        schedule_weight = max(0, schedule_weight)
        
        score = MAIZXScore(
            cfp=cfp,
            fcfp=fcfp,
            efficiency=efficiency,
            schedule_weight=schedule_weight
        )
        score.calculate(self.maizx_weights)
        return score
    
    # =========================================================================
    # DYNAMIC SLACK - Using Real Forecast Data
    # =========================================================================
    
    def calculate_dynamic_slack(
        self,
        forecast: List[RealForecastSlot],
        current_intensity: float,
        base_max_wait: float
    ) -> Tuple[float, str]:
        """
        Calculate dynamic slack using REAL forecast data.
        
        Extends wait window if real forecast shows better opportunity just beyond.
        """
        if not self.dynamic_slack or not forecast:
            return base_max_wait, "static (no forecast)"
        
        now = datetime.now(timezone.utc)
        extended_window = min(base_max_wait * 1.5, 48)
        
        best_in_window = current_intensity
        best_beyond_window = current_intensity
        best_beyond_time = None
        
        for slot in forecast:
            hours_away = (slot.time_from - now).total_seconds() / 3600
            if hours_away < 0:
                continue
            
            if hours_away <= base_max_wait:
                best_in_window = min(best_in_window, slot.intensity)
            elif hours_away <= extended_window:
                if slot.intensity < best_beyond_window:
                    best_beyond_window = slot.intensity
                    best_beyond_time = slot.time_from
        
        # Extend if >20% better opportunity exists just beyond window
        if best_beyond_window < best_in_window * 0.8 and best_beyond_time:
            savings_boost = (best_in_window - best_beyond_window) / current_intensity * 100
            hours_to_best = (best_beyond_time - now).total_seconds() / 3600
            extended_wait = min(hours_to_best + 0.5, extended_window)
            return extended_wait, f"extended to {extended_wait:.1f}h for {savings_boost:.0f}% extra savings"
        
        return base_max_wait, "optimal within window"
    
    # =========================================================================
    # Î±-FAIR ALLOCATION - Using Real Selection History
    # =========================================================================
    
    def apply_alpha_fair_adjustment(self, base_score: float, region: str) -> float:
        """
        Apply Î±-fair adjustment based on actual region selection history.
        """
        if self.alpha_fairness >= 1.0:
            return base_score
        
        total = sum(self.region_selection_history.values()) + 1
        region_count = self.region_selection_history.get(region, 0) + 1
        
        selection_ratio = region_count / total
        fairness_penalty = selection_ratio ** (1 - self.alpha_fairness)
        
        return base_score * (1 - fairness_penalty * 0.1)
    
    def record_region_selection(self, region: str):
        """Record a region selection for Î±-fair tracking."""
        self.region_selection_history[region] = self.region_selection_history.get(region, 0) + 1

    # =========================================================================
    # STRATEGY EVALUATION - Using Real Data Only
    # =========================================================================
    
    def evaluate_run_now(
        self,
        current_region: str,
        current_intensity: float,
        renewable_pct: float,
        criticality_config: CriticalityConfig
    ) -> StrategyOption:
        """Evaluate RUN_NOW strategy using real current data."""
        maizx = self.calculate_maizx_score(
            current_intensity=current_intensity,
            target_intensity=current_intensity,
            forecast_avg=current_intensity,
            renewable_pct=renewable_pct,
            wait_hours=0,
            max_wait_hours=criticality_config.max_wait_hours
        )
        
        return StrategyOption(
            strategy=Strategy.RUN_NOW,
            target_region=current_region,
            scheduled_time=datetime.now(timezone.utc),
            wait_hours=0,
            current_intensity=current_intensity,
            target_intensity=current_intensity,
            carbon_savings_percent=0,
            score=maizx.total,
            maizx_score=maizx,
            data_source="Real-time API",
            reason="Execute immediately in current region"
        )
    
    def evaluate_time_shift(
        self,
        current_region: str,
        current_intensity: float,
        forecast: List[RealForecastSlot],
        criticality_config: CriticalityConfig,
        renewable_pct: float,
        raw_grid_intensity: float = None
    ) -> Optional[StrategyOption]:
        """
        Evaluate TIME_SHIFT using REAL UK Grid ESO forecast data.
        Finds optimal future time slot within wait window.
        
        Note: Forecast data is raw grid intensity, so we need to:
        1. Compare forecast slots against raw grid intensity (not DC-adjusted)
        2. Convert best slot to DC-adjusted intensity for final comparison
        """
        if not self.allow_time_shift or not forecast:
            return None
        
        now = datetime.now(timezone.utc)
        
        # Get AWS DC metrics for current region to convert forecast to DC intensity
        dc_metrics = self.AWS_DC_METRICS.get(current_region)
        if not dc_metrics:
            dc_metrics = AWSDataCenterMetrics(current_region, 80, 1.15)
        
        # Use raw grid intensity for forecast comparison (forecast is raw grid data)
        # If not provided, estimate from DC intensity
        if raw_grid_intensity is None:
            # Reverse calculate: DC = Grid Ã— (1 - renewable%) Ã— PUE
            # Grid = DC / ((1 - renewable%) Ã— PUE)
            factor = (1 - dc_metrics.aws_renewable_pct / 100) * dc_metrics.pue
            raw_grid_intensity = current_intensity / factor if factor > 0 else current_intensity
        
        # Apply dynamic slack using real forecast (raw grid values)
        max_wait, slack_reason = self.calculate_dynamic_slack(
            forecast, raw_grid_intensity, criticality_config.max_wait_hours
        )
        
        # Find best slot in real forecast data (comparing raw grid intensities)
        best_slot = None
        best_raw_intensity = raw_grid_intensity
        
        for slot in forecast:
            hours_away = (slot.time_from - now).total_seconds() / 3600
            if hours_away < 0.5 or hours_away > max_wait:
                continue
            
            # Apply wait penalty to raw grid intensity
            penalty = hours_away * criticality_config.wait_penalty_per_hour
            effective_intensity = slot.intensity + penalty
            
            if effective_intensity < best_raw_intensity:
                best_raw_intensity = slot.intensity
                best_slot = slot
        
        # Check if we found a better slot (at least 10% improvement in raw grid)
        if not best_slot or best_slot.intensity >= raw_grid_intensity * 0.9:
            return None
        
        # Convert best slot's raw grid intensity to DC-adjusted intensity
        best_dc_intensity = dc_metrics.calculate_dc_intensity(best_slot.intensity)
        
        wait_hours = (best_slot.time_from - now).total_seconds() / 3600
        
        # Calculate savings using DC-adjusted intensities for fair comparison
        savings = (current_intensity - best_dc_intensity) / current_intensity * 100 if current_intensity > 0 else 0
        
        if savings < self.min_savings_percent:
            return None
        
        # Calculate forecast average for MAIZX (convert to DC-adjusted)
        raw_forecast_avg = sum(s.intensity for s in forecast[:12]) / min(len(forecast), 12)
        forecast_avg_dc = dc_metrics.calculate_dc_intensity(raw_forecast_avg)
        
        maizx = self.calculate_maizx_score(
            current_intensity=current_intensity,
            target_intensity=best_dc_intensity,
            forecast_avg=forecast_avg_dc,
            renewable_pct=renewable_pct,
            wait_hours=wait_hours,
            max_wait_hours=max_wait
        )
        
        return StrategyOption(
            strategy=Strategy.TIME_SHIFT,
            target_region=current_region,
            scheduled_time=best_slot.time_from,
            wait_hours=wait_hours,
            current_intensity=current_intensity,
            target_intensity=best_dc_intensity,  # DC-adjusted intensity
            carbon_savings_percent=savings,
            score=maizx.total,
            maizx_score=maizx,
            data_source=f"UK Grid ESO forecast ({slack_reason})",
            reason=f"Wait {wait_hours:.1f}h: Grid {best_slot.intensity:.0f} Ã— (1-{dc_metrics.aws_renewable_pct/100:.0%}) Ã— {dc_metrics.pue} = {best_dc_intensity:.1f} gCO2/kWh ({best_slot.index})"
        )
    
    def evaluate_space_shift(
        self,
        current_region: str,
        current_intensity: float,
        regions_data: Dict[str, RegionData],
        criticality_config: CriticalityConfig
    ) -> Optional[StrategyOption]:
        """
        Evaluate SPACE_SHIFT using REAL ElectricityMaps data.
        Finds cleanest region from real-time carbon intensity.
        """
        if not self.allow_space_shift or not criticality_config.allow_region_switch:
            return None
        
        if not regions_data:
            return None
        
        # Find best region from real data
        best_region = None
        best_data = None
        best_score = -1
        
        for region, data in regions_data.items():
            if region == current_region:
                continue
            
            savings = (current_intensity - data.carbon_intensity) / current_intensity * 100
            if savings < self.min_savings_percent:
                continue
            
            # Calculate MAIZX score for this region
            maizx = self.calculate_maizx_score(
                current_intensity=current_intensity,
                target_intensity=data.carbon_intensity,
                forecast_avg=data.carbon_intensity,  # Use current as proxy
                renewable_pct=data.renewable_percentage,
                wait_hours=0,
                max_wait_hours=criticality_config.max_wait_hours
            )
            
            # Apply Î±-fair adjustment
            adjusted_score = self.apply_alpha_fair_adjustment(maizx.total, region)
            
            # Apply region switch cost (reduced from 0.1 to 0.02 to prioritize carbon savings)
            # Research shows carbon savings should outweigh operational costs
            adjusted_score -= criticality_config.region_switch_cost * 0.02
            
            if adjusted_score > best_score:
                best_score = adjusted_score
                best_region = region
                best_data = data
        
        if not best_region or not best_data:
            return None
        
        savings = (current_intensity - best_data.carbon_intensity) / current_intensity * 100
        
        maizx = self.calculate_maizx_score(
            current_intensity=current_intensity,
            target_intensity=best_data.carbon_intensity,
            forecast_avg=best_data.carbon_intensity,
            renewable_pct=best_data.renewable_percentage,
            wait_hours=0,
            max_wait_hours=criticality_config.max_wait_hours
        )
        
        return StrategyOption(
            strategy=Strategy.SPACE_SHIFT,
            target_region=best_region,
            scheduled_time=datetime.now(timezone.utc),
            wait_hours=0,
            current_intensity=current_intensity,
            target_intensity=best_data.carbon_intensity,
            carbon_savings_percent=savings,
            score=best_score,
            maizx_score=maizx,
            data_source=f"ElectricityMaps ({best_data.zone}) + AWS DC (PUE={best_data.aws_pue}, {best_data.aws_renewable_pct}% renewable)",
            reason=f"Run in {best_region}: Grid={best_data.grid_intensity:.0f} Ã— (1-{best_data.aws_renewable_pct/100:.0%}) Ã— {best_data.aws_pue} = {best_data.carbon_intensity:.1f} gCO2/kWh"
        )
    
    def evaluate_hybrid(
        self,
        current_region: str,
        current_intensity: float,
        forecast: List[RealForecastSlot],
        regions_data: Dict[str, RegionData],
        criticality_config: CriticalityConfig
    ) -> Optional[StrategyOption]:
        """
        Evaluate HYBRID strategy using REAL data from both sources.
        Combines time shift + space shift for maximum savings.
        """
        if not self.allow_hybrid:
            return None
        
        if not forecast or not regions_data:
            return None
        
        now = datetime.now(timezone.utc)
        max_wait = criticality_config.max_wait_hours
        
        best_option = None
        best_score = -1
        
        # For each region, find best future time
        for region, data in regions_data.items():
            if region == current_region:
                continue
            
            # Use UK forecast as proxy for timing (best available)
            for slot in forecast:
                hours_away = (slot.time_from - now).total_seconds() / 3600
                if hours_away < 0.5 or hours_away > max_wait:
                    continue
                
                # Estimate target intensity: region's current + forecast trend
                intensity_trend = slot.intensity / current_intensity
                estimated_target = data.carbon_intensity * intensity_trend
                
                savings = (current_intensity - estimated_target) / current_intensity * 100
                if savings < self.min_savings_percent * 1.5:  # Higher threshold for hybrid
                    continue
                
                penalty = hours_away * criticality_config.wait_penalty_per_hour
                penalty += criticality_config.region_switch_cost
                
                maizx = self.calculate_maizx_score(
                    current_intensity=current_intensity,
                    target_intensity=estimated_target,
                    forecast_avg=slot.intensity,
                    renewable_pct=data.renewable_percentage,
                    wait_hours=hours_away,
                    max_wait_hours=max_wait
                )
                
                adjusted_score = self.apply_alpha_fair_adjustment(maizx.total, region)
                adjusted_score -= penalty * 0.05
                
                if adjusted_score > best_score:
                    best_score = adjusted_score
                    best_option = StrategyOption(
                        strategy=Strategy.HYBRID,
                        target_region=region,
                        scheduled_time=slot.time_from,
                        wait_hours=hours_away,
                        current_intensity=current_intensity,
                        target_intensity=estimated_target,
                        carbon_savings_percent=savings,
                        score=adjusted_score,
                        maizx_score=maizx,
                        data_source=f"UK Grid ESO + ElectricityMaps ({data.zone})",
                        reason=f"Wait {hours_away:.1f}h then run in {region} (~{estimated_target:.0f} gCO2/kWh)"
                    )
        
        return best_option

    # =========================================================================
    # MAIN DECISION ENGINE
    # =========================================================================
    
    def get_optimal_strategy(
        self,
        pipeline_name: str,
        current_region: str = 'eu-west-2',
        criticality: Criticality = Criticality.NORMAL
    ) -> SchedulingDecision:
        """
        Get optimal scheduling strategy using ONLY real API data.
        
        Fetches live data from:
        - UK National Grid ESO (current intensity + 48h forecast)
        - ElectricityMaps (all configured AWS regions)
        """
        print(f"\n{'='*60}")
        print(f"Carbon-Aware Scheduler v2.0 - Real Data Only")
        print(f"{'='*60}")
        print(f"Pipeline: {pipeline_name}")
        print(f"Current Region: {current_region}")
        print(f"Criticality: {criticality.value}")
        print(f"{'='*60}\n")
        
        criticality_config = self.DEFAULT_CRITICALITY[criticality]
        data_sources = []
        options = []
        
        # Fetch REAL current intensity
        print("ðŸ“¡ Fetching real-time carbon data...")
        
        current_intensity, current_index, uk_source = self.fetch_uk_current()
        data_sources.append(uk_source)
        
        if current_intensity is None:
            # Fallback to ElectricityMaps for current region
            region_data, em_source = self.fetch_region_intensity(current_region)
            data_sources.append(em_source)
            if region_data:
                current_intensity = region_data.carbon_intensity
                current_index = "from ElectricityMaps"
            else:
                # Cannot proceed without real data
                return SchedulingDecision(
                    recommended_strategy=Strategy.RUN_NOW,
                    target_region=current_region,
                    scheduled_time=datetime.now(timezone.utc),
                    wait_hours=0,
                    current_intensity=0,
                    target_intensity=0,
                    carbon_savings_percent=0,
                    all_options=[],
                    criticality=criticality,
                    pipeline_name=pipeline_name,
                    decision_reason="ERROR: Could not fetch real carbon data from any source",
                    data_sources=data_sources
                )
        
        print(f"âœ“ Current intensity: {current_intensity:.0f} gCO2/kWh ({current_index})")
        
        # Check if already excellent
        if current_intensity <= self.excellent_threshold:
            print(f"âœ“ Intensity below excellent threshold ({self.excellent_threshold})")
            return SchedulingDecision(
                recommended_strategy=Strategy.RUN_NOW,
                target_region=current_region,
                scheduled_time=datetime.now(timezone.utc),
                wait_hours=0,
                current_intensity=current_intensity,
                target_intensity=current_intensity,
                carbon_savings_percent=0,
                all_options=[],
                criticality=criticality,
                pipeline_name=pipeline_name,
                decision_reason=f"Current intensity ({current_intensity:.0f}) is excellent - run immediately",
                data_sources=data_sources
            )
        
        # Fetch REAL forecast
        print("ðŸ“¡ Fetching 48h forecast...")
        forecast, forecast_source = self.fetch_uk_forecast_48h()
        data_sources.append(forecast_source)
        print(f"âœ“ {forecast_source}")
        
        # Fetch REAL generation mix for renewable %
        gen_mix, gen_source = self.fetch_uk_generation_mix()
        renewable_pct = 0
        if gen_mix:
            renewable_sources = ['wind', 'solar', 'hydro', 'nuclear', 'biomass']
            renewable_pct = sum(gen_mix.get(s, 0) for s in renewable_sources)
            print(f"âœ“ UK renewable: {renewable_pct:.1f}%")
        
        # Fetch REAL data for all regions (with AWS DC metrics applied)
        print("ðŸ“¡ Fetching regional carbon data (with AWS DC metrics)...")
        regions_data, region_sources = self.fetch_all_regions()
        data_sources.extend(region_sources)
        print(f"âœ“ Got data for {len(regions_data)} regions")
        
        # Show AWS DC intensity calculation for each region
        print("\nðŸ“Š AWS Data Center Intensity by Region:")
        print("   Formula: Grid Ã— (1 - AWS_Renewable%) Ã— PUE = DC_Intensity")
        for region, data in sorted(regions_data.items(), key=lambda x: x[1].carbon_intensity):
            print(f"   {region}: {data.grid_intensity:.0f} Ã— (1-{data.aws_renewable_pct/100:.0%}) Ã— {data.aws_pue} = {data.carbon_intensity:.1f} gCO2/kWh")
        
        # Use DC-adjusted intensity for current region (for fair comparison)
        # The raw grid intensity is stored separately for display
        raw_grid_intensity = current_intensity  # Keep raw value for reference
        if current_region in regions_data:
            current_dc_data = regions_data[current_region]
            current_intensity = current_dc_data.carbon_intensity  # Use DC-adjusted
            print(f"\nâœ“ Current region DC intensity: {current_intensity:.1f} gCO2/kWh (Grid: {raw_grid_intensity:.0f})")
        
        # Evaluate all strategies with REAL data
        print("\nðŸ“Š Evaluating strategies with real data...")
        
        # 1. RUN_NOW
        run_now = self.evaluate_run_now(
            current_region, current_intensity, renewable_pct, criticality_config
        )
        options.append(run_now)
        print(f"  RUN_NOW: score={run_now.score:.3f}")
        
        # 2. TIME_SHIFT (pass raw grid intensity for proper forecast comparison)
        time_shift = self.evaluate_time_shift(
            current_region, current_intensity, forecast, criticality_config, renewable_pct,
            raw_grid_intensity=raw_grid_intensity
        )
        if time_shift:
            options.append(time_shift)
            print(f"  TIME_SHIFT: {time_shift.carbon_savings_percent:.1f}% savings in {time_shift.wait_hours:.1f}h, score={time_shift.score:.3f}")
        
        # 3. SPACE_SHIFT
        space_shift = self.evaluate_space_shift(
            current_region, current_intensity, regions_data, criticality_config
        )
        if space_shift:
            options.append(space_shift)
            print(f"  SPACE_SHIFT: {space_shift.carbon_savings_percent:.1f}% savings to {space_shift.target_region}, score={space_shift.score:.3f}")
        
        # 4. HYBRID
        hybrid = self.evaluate_hybrid(
            current_region, current_intensity, forecast, regions_data, criticality_config
        )
        if hybrid:
            options.append(hybrid)
            print(f"  HYBRID: {hybrid.carbon_savings_percent:.1f}% savings, score={hybrid.score:.3f}")
        
        # Select best option
        best = max(options, key=lambda x: x.score)
        
        # Record selection for Î±-fair tracking
        self.record_region_selection(best.target_region)
        
        print(f"\nâœ… Recommended: {best.strategy.value.upper()}")
        print(f"   Target: {best.target_region}")
        print(f"   Savings: {best.carbon_savings_percent:.1f}%")
        print(f"   Reason: {best.reason}")
        
        # Get AWS DC metrics for target region
        target_dc = self.AWS_DC_METRICS.get(best.target_region)
        target_region_data = regions_data.get(best.target_region)
        grid_intensity = target_region_data.grid_intensity if target_region_data else current_intensity
        aws_renewable = target_dc.aws_renewable_pct if target_dc else 80
        aws_pue = target_dc.pue if target_dc else 1.15
        
        return SchedulingDecision(
            recommended_strategy=best.strategy,
            target_region=best.target_region,
            scheduled_time=best.scheduled_time,
            wait_hours=best.wait_hours,
            current_intensity=current_intensity,
            target_intensity=best.target_intensity,
            carbon_savings_percent=best.carbon_savings_percent,
            all_options=options,
            criticality=criticality,
            pipeline_name=pipeline_name,
            decision_reason=best.reason,
            data_sources=list(set(data_sources)),
            grid_intensity=grid_intensity,
            aws_renewable_pct=aws_renewable,
            aws_pue=aws_pue
        )


def load_config_from_env() -> Dict:
    """Load configuration from .env file."""
    config = {}
    env_path = os.path.join(os.path.dirname(__file__), 'config', '.env')
    
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    # Strip inline comments (# ...) from value
                    value = value.split('#')[0].strip()
                    config[key.strip()] = value
    
    # Also check environment variables
    for key in os.environ:
        if key.startswith(('MAIZX_', 'ALPHA_', 'DYNAMIC_', 'ALLOW_', 'EXCELLENT_', 'MIN_SAVINGS', 'ELECTRICITYMAPS')):
            config[key] = os.environ[key]
    
    return config


def main():
    """CLI entry point for carbon scheduler."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Carbon-Aware Scheduling Decision Engine v2.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python carbon_scheduler.py --pipeline my-pipeline
  python carbon_scheduler.py --pipeline my-pipeline --criticality high
  python carbon_scheduler.py --pipeline my-pipeline --region eu-central-1
  python carbon_scheduler.py --pipeline my-pipeline --json
        """
    )
    parser.add_argument('--pipeline', '-p', required=True, help='Pipeline name')
    parser.add_argument('--region', '-r', default='eu-west-2', help='Current AWS region')
    parser.add_argument('--criticality', '-c', default='normal',
                        choices=['critical', 'high', 'normal', 'low'],
                        help='Pipeline criticality level')
    parser.add_argument('--json', '-j', action='store_true', help='Output as JSON')
    
    args = parser.parse_args()
    
    # Load config
    config = load_config_from_env()
    
    # Create scheduler
    scheduler = CarbonScheduler(config)
    
    # Get decision
    criticality = Criticality(args.criticality)
    decision = scheduler.get_optimal_strategy(
        pipeline_name=args.pipeline,
        current_region=args.region,
        criticality=criticality
    )
    
    if args.json:
        print(json.dumps(decision.to_dict(), indent=2))
    else:
        print(f"\n{'='*60}")
        print("SCHEDULING DECISION")
        print(f"{'='*60}")
        print(f"Strategy: {decision.recommended_strategy.value.upper()}")
        print(f"Target Region: {decision.target_region}")
        if decision.scheduled_time:
            print(f"Scheduled Time: {decision.scheduled_time.strftime('%Y-%m-%d %H:%M UTC')}")
        print(f"Wait Hours: {decision.wait_hours:.1f}")
        print(f"\n--- AWS Data Center Intensity Calculation ---")
        print(f"Grid Intensity: {decision.grid_intensity:.0f} gCO2/kWh")
        print(f"AWS Renewable Energy: {decision.aws_renewable_pct}%")
        print(f"AWS PUE: {decision.aws_pue}")
        print(f"DC Intensity: {decision.grid_intensity:.0f} Ã— (1-{decision.aws_renewable_pct/100:.0%}) Ã— {decision.aws_pue} = {decision.target_intensity:.1f} gCO2/kWh")
        print(f"----------------------------------------------")
        print(f"\nCurrent Intensity: {decision.current_intensity:.0f} gCO2/kWh")
        print(f"Target Intensity: {decision.target_intensity:.1f} gCO2/kWh")
        print(f"Carbon Savings: {decision.carbon_savings_percent:.1f}%")
        print(f"Reason: {decision.decision_reason}")
        print(f"\nData Sources: {', '.join(decision.data_sources)}")
        print(f"Options Evaluated: {len(decision.all_options)}")


if __name__ == '__main__':
    main()
